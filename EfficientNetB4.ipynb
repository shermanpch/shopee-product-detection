{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:14.349263Z",
     "start_time": "2020-07-01T12:23:11.878141Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.applications.efficientnet import EfficientNetB4, preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:14.380177Z",
     "start_time": "2020-07-01T12:23:14.352255Z"
    }
   },
   "outputs": [],
   "source": [
    "randomSeed = 42\n",
    "\n",
    "ia.seed(randomSeed)\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        iaa.Affine(rotate=(-15, 15)),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.GaussianBlur((0, 2.0)),\n",
    "        iaa.ElasticTransformation(alpha=(0, 70), sigma=9),\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.05), per_channel=True),\n",
    "        iaa.ChannelShuffle(p=0.5),\n",
    "    ],\n",
    "    random_order=False,\n",
    ")\n",
    "\n",
    "class CutMixImageDataGenerator():\n",
    "    def __init__(self, generator1, generator2, img_size, batch_size):\n",
    "        self.batch_index = 0\n",
    "        self.samples = generator1.samples\n",
    "        self.class_indices = generator1.class_indices\n",
    "        self.generator1 = generator1\n",
    "        self.generator2 = generator2\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def reset_index(self):  # Ordering Reset (If Shuffle is True, Shuffle Again)\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "        self.generator1.reset()\n",
    "        self.generator2.reset()\n",
    "        self.reset_index()\n",
    "\n",
    "    def get_steps_per_epoch(self):\n",
    "        quotient, remainder = divmod(self.samples, self.batch_size)\n",
    "        return (quotient + 1) if remainder else quotient\n",
    "    \n",
    "    def __len__(self):\n",
    "        self.get_steps_per_epoch()\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.batch_index == 0: self.reset()\n",
    "\n",
    "        crt_idx = self.batch_index * self.batch_size\n",
    "        if self.samples > crt_idx + self.batch_size:\n",
    "            self.batch_index += 1\n",
    "        else:  # If current index over number of samples\n",
    "            self.batch_index = 0\n",
    "\n",
    "        reshape_size = self.batch_size\n",
    "        last_step_start_idx = (self.get_steps_per_epoch()-1) * self.batch_size\n",
    "        if crt_idx == last_step_start_idx:\n",
    "            reshape_size = self.samples - last_step_start_idx\n",
    "            \n",
    "        X_1, y_1 = self.generator1.next()\n",
    "        X_2, y_2 = self.generator2.next()\n",
    "        \n",
    "        cut_ratio = np.random.beta(a=1, b=1, size=reshape_size)\n",
    "        cut_ratio = np.clip(cut_ratio, 0.2, 0.8)\n",
    "        label_ratio = cut_ratio.reshape(reshape_size, 1)\n",
    "        cut_img = X_2\n",
    "\n",
    "        X = X_1\n",
    "        for i in range(reshape_size):\n",
    "            cut_size = int((self.img_size-1) * cut_ratio[i])\n",
    "            y1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "            x1 = random.randint(0, (self.img_size-1) - cut_size)\n",
    "            y2 = y1 + cut_size\n",
    "            x2 = x1 + cut_size\n",
    "            cut_arr = cut_img[i][y1:y2, x1:x2]\n",
    "            cutmix_img = X_1[i]\n",
    "            cutmix_img[y1:y2, x1:x2] = cut_arr\n",
    "            X[i] = cutmix_img\n",
    "            \n",
    "        X = seq.augment_images(X)  # Sequential of imgaug\n",
    "        y = y_1 * (1 - (label_ratio ** 2)) + y_2 * (label_ratio ** 2)\n",
    "        return X, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:25.136838Z",
     "start_time": "2020-07-01T12:23:14.385164Z"
    }
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv('../train.csv')\n",
    "trainingDirectory = '../trainAllResized'\n",
    "target = trainDF['category'].apply(lambda c: str(c).zfill(2))\n",
    "noClasses = len(np.unique(target))\n",
    "imageWidth = 229\n",
    "imageHeight = 229\n",
    "imageDimension = (imageWidth, imageHeight)\n",
    "batchSize = 16\n",
    "validationRatio = 0.2\n",
    "preprocess = preprocess_input\n",
    "    \n",
    "X_train, X_val, y_train, y_val = train_test_split(trainDF[['filename']], target, \n",
    "                                                  test_size=validationRatio, random_state=randomSeed,\n",
    "                                                  stratify=target)\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "trainDataGenerator = ImageDataGenerator(horizontal_flip=True,\n",
    "                                        brightness_range=[0.6, 1.4],\n",
    "                                        preprocessing_function=preprocess)\n",
    "\n",
    "trainGenerator1 = trainDataGenerator.flow_from_dataframe(\n",
    "                dataframe=train,\n",
    "                directory=trainingDirectory,\n",
    "                x_col='filename',\n",
    "                y_col='category',\n",
    "                target_size=imageDimension,\n",
    "                batch_size=batchSize,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "trainGenerator2 = trainDataGenerator.flow_from_dataframe(\n",
    "                dataframe=train,\n",
    "                directory=trainingDirectory,\n",
    "                x_col='filename',\n",
    "                y_col='category',\n",
    "                target_size=imageDimension,\n",
    "                batch_size=batchSize,\n",
    "                class_mode='categorical',\n",
    "                shuffle=True)\n",
    "\n",
    "# CutMixImageDataGenerator\n",
    "trainGenerator = CutMixImageDataGenerator(\n",
    "    generator1=trainGenerator1,\n",
    "    generator2=trainGenerator2,\n",
    "    img_size=imageDimension[0],\n",
    "    batch_size=batchSize)\n",
    "\n",
    "\n",
    "valDataGenerator = ImageDataGenerator(preprocessing_function=preprocess)\n",
    "\n",
    "valGenerator = valDataGenerator.flow_from_dataframe(\n",
    "            dataframe=val,\n",
    "            directory=trainingDirectory,\n",
    "            x_col='filename',\n",
    "            y_col='category',\n",
    "            target_size=imageDimension,\n",
    "            batch_size=batchSize,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:25.168847Z",
     "start_time": "2020-07-01T12:23:25.137827Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                classes=np.unique(trainGenerator1.classes), \n",
    "                y=trainGenerator1.classes)\n",
    "\n",
    "class_weight = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:33.666245Z",
     "start_time": "2020-07-01T12:23:25.171803Z"
    }
   },
   "outputs": [],
   "source": [
    "baseModel = EfficientNetB4(include_top=False, weights='imagenet', input_shape=(imageWidth, imageHeight, 3))\n",
    "model = Sequential()\n",
    "model.add(baseModel)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=regularizers.l2(1e-3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(noClasses, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=5e-05),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.load_weights('checkpoint/model.18-0.8034-0.8112-0.7413.h5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-01T12:23:49.248589Z",
     "start_time": "2020-07-01T12:23:33.670258Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint/model.{epoch:02d}-{val_loss:.4f}-{val_acc:.4f}-{acc:.4f}.h5'\n",
    "checkpointCallback = ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                                            save_weights_only=True, \n",
    "                                            monitor='val_acc',\n",
    "                                            mode='max',\n",
    "                                            save_best_only=True)\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='val_acc', mode='max', patience=16, verbose=1)\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=4, min_lr=1e-6, verbose=1)\n",
    "\n",
    "history = model.fit(trainGenerator, \n",
    "                  steps_per_epoch=trainGenerator1.n//trainGenerator1.batch_size, \n",
    "                  epochs=100,\n",
    "                  validation_data=valGenerator, \n",
    "                  validation_steps=valGenerator.n//valGenerator.batch_size,\n",
    "                  verbose=1,\n",
    "                  class_weight=class_weight,\n",
    "                  initial_epoch=18,\n",
    "                  callbacks=[checkpointCallback, earlyStop, reduceLR])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
